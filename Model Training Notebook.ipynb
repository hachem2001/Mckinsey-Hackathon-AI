{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d83f88",
   "metadata": {
    "id": "06d83f88"
   },
   "source": [
    "# Methane detection hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "70300d5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70300d5a",
    "outputId": "7a34783f-a681-45ab-973f-0d83ff6d49bc"
   },
   "outputs": [],
   "source": [
    "# [Hachem] pip install all necessary packages\n",
    "# [Hachem] Here it is commented for python environment reasons\n",
    "# %pip install pandas rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1047fae5",
   "metadata": {
    "id": "1047fae5"
   },
   "source": [
    "### 1. Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a02d292a-89f9-4d03-a3f3-3464cd052243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all used libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.plot import show, show_hist\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e7nhLDyHqc1_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7nhLDyHqc1_",
    "outputId": "dd67d614-8aa6-45a2-b1c2-908c00cb5f57"
   },
   "outputs": [],
   "source": [
    "# [Hachem] : Google collab specific charging of files. Necessary to be able to read files in google collab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "PREPENDING_PATH = \"AugmentData/\" # [Hachem] : Different for Google Drive, otherwise adapted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2cb7cd88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cb7cd88",
    "outputId": "bab808ae-4a46-48c0-815e-db39993aa68a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images : 4300\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images : \"+str(len(pd.read_csv(PREPENDING_PATH + \"metadata_aug.csv\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69562d1",
   "metadata": {
    "id": "d69562d1"
   },
   "source": [
    "### 2. Metadata and Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6d9be06f",
   "metadata": {
    "id": "6d9be06f"
   },
   "outputs": [],
   "source": [
    "# [Hachem] Load metadata\n",
    "METADATA = pd.read_csv(PREPENDING_PATH +  \"/metadata_aug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7cdaf547",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7cdaf547",
    "outputId": "d64901bb-19c9-4108-8638-8982a89a0f73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id_coord</th>\n",
       "      <th>plume</th>\n",
       "      <th>set</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>coord_x</th>\n",
       "      <th>coord_y</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230223</td>\n",
       "      <td>id_6675</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>31.528750</td>\n",
       "      <td>74.330625</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>images/plume/20230223_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230103</td>\n",
       "      <td>id_2542</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>35.538000</td>\n",
       "      <td>112.524000</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>images/plume/20230103_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230301</td>\n",
       "      <td>id_6546</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>21.060000</td>\n",
       "      <td>84.936667</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>images/plume/20230301_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230225</td>\n",
       "      <td>id_6084</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>26.756667</td>\n",
       "      <td>80.973333</td>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "      <td>images/plume/20230225_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230105</td>\n",
       "      <td>id_2012</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>40.770000</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>images/plume/20230105_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date id_coord plume    set        lat         lon  coord_x  coord_y  \\\n",
       "0  20230223  id_6675   yes  train  31.528750   74.330625       24       47   \n",
       "1  20230103  id_2542   yes  train  35.538000  112.524000       42       37   \n",
       "2  20230301  id_6546   yes  train  21.060000   84.936667       58       15   \n",
       "3  20230225  id_6084   yes  train  26.756667   80.973333       28       62   \n",
       "4  20230105  id_2012   yes  train  34.800000   40.770000       59       44   \n",
       "\n",
       "                                                path  \n",
       "0  images/plume/20230223_methane_mixing_ratio_id_...  \n",
       "1  images/plume/20230103_methane_mixing_ratio_id_...  \n",
       "2  images/plume/20230301_methane_mixing_ratio_id_...  \n",
       "3  images/plume/20230225_methane_mixing_ratio_id_...  \n",
       "4  images/plume/20230105_methane_mixing_ratio_id_...  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 5 elements of METADATA.\n",
    "METADATA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "pexFyC0Z1pun",
   "metadata": {
    "id": "pexFyC0Z1pun"
   },
   "outputs": [],
   "source": [
    "# Load GPU - hopefully ?\n",
    "# Set the device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1sZEFL4BtOz9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1sZEFL4BtOz9",
    "outputId": "503d7255-037b-4163-b527-f1a893880a72"
   },
   "outputs": [],
   "source": [
    "# [Hachem] Charger tout les fichiers\n",
    "plume_count = 0 # Total number of plume images\n",
    "no_plume_count = 0 # Total number of no plume images\n",
    "\n",
    "plume_arrays = [] # Store numpy representation of original plume images\n",
    "plume_positions = [] # Store positions of original plumes\n",
    "plume_arrays_ids = [] # Store the unique identifiers of each original plume\n",
    "plume_arrays_aug_imp = [] # Store numpy representation of augmented plume images\n",
    "plume_positions_aug_imp = [] # Store positions of augmented plumes\n",
    "plume_arrays_aug_imp_ids = [] # Store the unique identifiers of each augmented plume\n",
    "\n",
    "no_plume_arrays = [] # Store numpy representation of original non plume images\n",
    "no_plume_arrays_ids = [] # Store the unique identifiers of each original non plume\n",
    "no_plume_arrays_aug_imp = [] # Store numpy representation of augmented non plume images\n",
    "no_plume_arrays_aug_imp_ids = [] # Store the unique identifiers of each augmented non plume\n",
    "\n",
    "# [Hachem] Load all images.\n",
    "for index, row in METADATA.iterrows():\n",
    "    # [Hachem] String preprocessing\n",
    "    string_p = row.path.replace(\"\\\\\", \"/\")\n",
    "    string_p = string_p.replace(\"train/\", \"\")\n",
    "    string_p = string_p.replace(\".tif\", \"\")\n",
    "\n",
    "    # [Hachem] Load image\n",
    "    img = rasterio.open(PREPENDING_PATH + string_p + \".tif\")\n",
    "\n",
    "    # [Hachem] Load data into appropriate arrays\n",
    "    if (row.set == \"train\"): # or row.set == \"augmented_perfect\"):\n",
    "        if (row.plume == \"yes\"):\n",
    "            plume_arrays.append(img.read(1))\n",
    "            plume_positions.append([row.coord_x/64, row.coord_y/64])\n",
    "            plume_arrays_ids.append(str(row.date) + row.id_coord)\n",
    "            \n",
    "            plume_count += 1\n",
    "        elif (row.plume == \"no\"):\n",
    "            no_plume_arrays.append(img.read(1))\n",
    "            no_plume_arrays_ids.append(str(row.date) + row.id_coord)\n",
    "            \n",
    "            no_plume_count += 1\n",
    "    else:\n",
    "        if (row.plume == \"yes\"):\n",
    "            plume_arrays_aug_imp.append(img.read(1))\n",
    "            plume_positions_aug_imp.append([row.coord_x/64, row.coord_y/64])\n",
    "            plume_arrays_aug_imp_ids.append(str(row.date) + row.id_coord)\n",
    "            \n",
    "            plume_count += 1\n",
    "        elif (row.plume == \"no\"):\n",
    "            no_plume_arrays_aug_imp.append(img.read(1))\n",
    "            no_plume_arrays_aug_imp_ids.append(str(row.date) + row.id_coord)\n",
    "            \n",
    "            no_plume_count += 1\n",
    "    \n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "aBRBVMbREYN5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBRBVMbREYN5",
    "outputId": "7d249563-4371-4bbe-c068-9f7f909287f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of plumes :  2160\n",
      "Total number of non_plume :  2140\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of plumes : \", plume_count)\n",
    "print(\"Total number of non_plume : \", no_plume_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd00b8e-c656-45da-90fa-43a16cc45d8e",
   "metadata": {},
   "source": [
    "# 3. Set up Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "O0G9sgNj609d",
   "metadata": {
    "id": "O0G9sgNj609d"
   },
   "outputs": [],
   "source": [
    "# [Hachem] Preprocessing tools\n",
    "# Transform for set grayscale data to [0.0, 1.0], and then normalize it around median value 0.5\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))]) # Only one value because gray-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5GEfpmNUBk2x",
   "metadata": {
    "id": "5GEfpmNUBk2x"
   },
   "outputs": [],
   "source": [
    "# [Hachem] DataSet Loader\n",
    "# This is to be used in conjunction with Pytorch's torch.utils.data.DataLoader.\n",
    "# DataSet Loader for PlumeNoPlume classifier\n",
    "\n",
    "class PlumeNoPlumeDataSet(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch DataSet for PlumeNoPlume DataSet\n",
    "    Arguments :\n",
    "        - images_numpy : a numpy array of all the 3-dimensional numpy representation of images\n",
    "        - labels : all of the corresponding labels\n",
    "        - transform : pytorch transform, for normalizing data.\n",
    "    \"\"\"\n",
    "    def __init__(self, images_numpy, labels, transform=None):\n",
    "        self.data = images_numpy\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    # Self-explanatory\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Does the preprocessing of the image and returns numpy arrays of the data.\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.asarray(self.data[idx])\n",
    "        label = np.asarray(self.labels[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# DataSet Loader for Plume position network\n",
    "class PlumePositionDataSet(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch DataSet for PlumePosition DataSet\n",
    "    Arguments :\n",
    "        - images_numpy : same as PlumeNoPlumeDataSet\n",
    "        - positions : 2 D array with positions between 0 and 1 for of x then of y\n",
    "        - transform : same as PlumeNoPlumeDataSet\n",
    "    \"\"\"\n",
    "    def __init__(self, images_numpy, positions, transform=None):\n",
    "        self.data = images_numpy\n",
    "        self.positions = positions\n",
    "        self.transform = transform\n",
    "\n",
    "    # Self-explanatory\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Does the preprocessing of the image and returns numpy arrays of the data.\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.asarray(self.data[idx])\n",
    "        positions = np.asarray(self.positions[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, positions\n",
    "\n",
    "# [Hachem] : Prepares the training and validation sets with approriate ratio.\n",
    "def prepare_plume_noplume_train_validation(plume, plume_ids, no_plume, no_plume_ids, plume_aug, plume_aug_ids, no_plume_aug, no_plume_aug_ids, ratio):\n",
    "    \"\"\"\n",
    "    Splits data into train and validation\n",
    "    Inputs :\n",
    "        - plume : Plume images\n",
    "        - plume_ids : Unique Identifiers for Plume images\n",
    "        - no_plume : No Plume images\n",
    "        - no_plume_ids : Unique Identifiers for No Plume images\n",
    "        - plume_aug : Augmented Plume images\n",
    "        - plume_aug_ids : Unique Identifiers for Augmented Plume images\n",
    "        - no_plume_aug : Augmented No Plume images\n",
    "        - no_plume_aug_ids : Unique Identifiers for Augmented No Plume images\n",
    "        - ratio : probability to add to training instead of validation.\n",
    "    Returns :\n",
    "        - images_numpy_train, labels_train, images_numpy_validation, labels_validation\n",
    "    \"\"\"\n",
    "    images_numpy_train, labels_train, images_numpy_validation, labels_validation = [], [], [], []\n",
    "\n",
    "    # The following arrays are to make sure there is no augmented data of a validation-set image, in training set.\n",
    "    validation_plume_ids = []\n",
    "    validation_no_plume_ids = [] \n",
    "    \n",
    "    for i in range(len(no_plume)):\n",
    "        if (np.random.random() < ratio):\n",
    "            images_numpy_train.append(no_plume[i])\n",
    "            labels_train.append(0)\n",
    "        else:\n",
    "            images_numpy_validation.append(no_plume[i])\n",
    "            labels_validation.append(0)\n",
    "            validation_no_plume_ids.append(no_plume_ids[i])\n",
    "    \n",
    "    for i in range(len(plume)):\n",
    "        if (np.random.random() < ratio):\n",
    "            images_numpy_train.append(plume[i])\n",
    "            labels_train.append(1);\n",
    "        else:\n",
    "            images_numpy_validation.append(plume[i])\n",
    "            labels_validation.append(1);\n",
    "            validation_plume_ids.append(plume_ids[i])\n",
    "    \n",
    "    \n",
    "    for i in range(len(no_plume_aug)):\n",
    "        if (not no_plume_aug_ids[i] in validation_no_plume_ids):\n",
    "            images_numpy_train.append(no_plume_aug[i])\n",
    "            labels_train.append(0);\n",
    "\n",
    "    for i in range(len(plume_aug)):\n",
    "        if (not plume_aug_ids[i] in validation_plume_ids):\n",
    "            images_numpy_train.append(plume_aug[i])\n",
    "            labels_train.append(1);\n",
    "    \n",
    "    return np.array(images_numpy_train, dtype=np.float32), np.array(labels_train, dtype=np.float32), np.array(images_numpy_validation, dtype=np.float32), np.array(labels_validation, dtype=np.float32)\n",
    "\n",
    "def prepare_plume_positions_train_validation(plume, plume_ids, positions_plume, plume_aug, plume_aug_ids, positions_plume_aug, ratio):\n",
    "    \"\"\"\n",
    "    Prepares training and validation sets.\n",
    "    Input :\n",
    "        - plume : Plume images\n",
    "        - plume_ids : Identifiers of plume images\n",
    "        - positions_plume : Positions of plume images\n",
    "        - plume_aug : Augmented plume images\n",
    "        - plume_aug_ids : Identifiers of augmented plume images\n",
    "        - ratio : probabilistic split ratio.\n",
    "    Outputs :\n",
    "        - images_numpy_train, labels_train, images_numpy_validation, labels_validation\n",
    "    \"\"\"\n",
    "    images_numpy_train, positions_train, images_numpy_validation, positions_validation = [], [], [], []\n",
    "    \n",
    "    validation_plume_ids = []\n",
    "    \n",
    "    for i in range(len(plume)):\n",
    "        if (np.random.random() < ratio):\n",
    "            images_numpy_train.append(plume[i])\n",
    "            positions_train.append(positions_plume[i]);\n",
    "        else:\n",
    "          images_numpy_validation.append(plume[i])\n",
    "          positions_validation.append(positions_plume[i]);\n",
    "          validation_plume_ids.append(plume_ids[i])\n",
    "    \n",
    "    for i in range(len(plume_aug)):\n",
    "        if (not plume_aug_ids[i] in validation_plume_ids):\n",
    "            images_numpy_train.append(plume_aug[i])\n",
    "            positions_train.append(positions_plume_aug[i]);\n",
    "    \n",
    "    return np.array(images_numpy_train, dtype=np.float32), np.array(positions_train, dtype=np.float32), np.array(images_numpy_validation, dtype=np.float32), np.array(positions_validation, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "yq-o5sSsBCQC",
   "metadata": {
    "id": "yq-o5sSsBCQC"
   },
   "outputs": [],
   "source": [
    "# Hachem : Prepare data sets\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TRAIN_SET_RATIO = 0.7 # Set to 0.8 when not augmenting data. Reason being that we don't include augmented images of validation set images in training set.\n",
    "\n",
    "# Seperate train and validation sets for PlumeNoPlume\n",
    "images_numpy_train, labels_train, images_numpy_validation, labels_validation = prepare_plume_noplume_train_validation(plume_arrays,\n",
    "                                                                                                    plume_arrays_ids,\n",
    "                                                                                                    \n",
    "                                                                                                    no_plume_arrays,\n",
    "                                                                                                    no_plume_arrays_ids,\n",
    "                                                                                                    \n",
    "                                                                                                    plume_arrays_aug_imp,\n",
    "                                                                                                    plume_arrays_aug_imp_ids,\n",
    "                                                                                                    \n",
    "                                                                                                    no_plume_arrays_aug_imp,\n",
    "                                                                                                    no_plume_arrays_aug_imp_ids,\n",
    "                                                                                                    \n",
    "                                                                                                    TRAIN_SET_RATIO)\n",
    "\n",
    "# Seperate train and validation sets for Position estimation\n",
    "images_numpy_train_p, positions_train_p, images_numpy_validation_p, positions_validation_p = prepare_plume_positions_train_validation(plume_arrays,\n",
    "                                                                                                                    plume_arrays_ids,\n",
    "                                                                                                                    plume_positions,\n",
    "                                                                                                                    \n",
    "                                                                                                                    plume_arrays_aug_imp,\n",
    "                                                                                                                    plume_arrays_aug_imp_ids,\n",
    "                                                                                                                    plume_positions_aug_imp,\n",
    "                                                                                                                    \n",
    "                                                                                                                    TRAIN_SET_RATIO)\n",
    "\n",
    "# Use Appropriate DataLoaders for PlumeNoPlume\n",
    "train_set_plumenoplume = PlumeNoPlumeDataSet(images_numpy_train, labels_train, transform = transform);\n",
    "validation_set_plumenoplume = PlumeNoPlumeDataSet(images_numpy_validation, labels_validation, transform = transform);\n",
    "\n",
    "# Use Appropriate DataLoaders for PlumePositions\n",
    "train_set_positions = PlumePositionDataSet(images_numpy_train_p, positions_train_p, transform = transform);\n",
    "validation_set_positions = PlumePositionDataSet(images_numpy_validation_p, positions_validation_p, transform = transform);\n",
    "\n",
    "# Create DataLoaders for PlumeNoPlume\n",
    "trainloader_plumenoplume = torch.utils.data.DataLoader(train_set_plumenoplume, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "validationloader_plumenoplume = torch.utils.data.DataLoader(validation_set_plumenoplume, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Create DataLoaders for PlumePositions\n",
    "trainloader_positions = torch.utils.data.DataLoader(train_set_positions, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "validationloader_positions = torch.utils.data.DataLoader(validation_set_positions, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('no_plume', 'plume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4bd72cf6-3796-4c7e-8ed5-a5fd54d7f295",
   "metadata": {
    "id": "UHOrDj-X87Zv"
   },
   "outputs": [],
   "source": [
    "# Start with CNN classes\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\" Classifier model class \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding_mode='zeros', device=DEVICE)  # Increased filters\n",
    "        self.bn1 = nn.BatchNorm2d(16, device=DEVICE)  # Batch normalization\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dp1 = nn.Dropout2d(0.25)  # Dropout\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, device=DEVICE)  # Increased filters\n",
    "        self.bn2 = nn.BatchNorm2d(32, device=DEVICE)  # Batch normalization\n",
    "\n",
    "        self.fc1 = nn.Linear(5408, 120, device=DEVICE)  # Adjusted input size\n",
    "        self.dp2 = nn.Dropout(0.5)  # Dropout after fully connected\n",
    "        self.fc2 = nn.Linear(120, 48, device=DEVICE)\n",
    "        self.fc3 = nn.Linear(48, 5, device=DEVICE)\n",
    "        self.fc4 = nn.Linear(5, 1, device=DEVICE)\n",
    "\n",
    "    def _up_to_features(self, x):\n",
    "        # Conv1 + BatchNorm + Activation\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dp1(x)\n",
    "\n",
    "        # Conv2 + BatchNorm + Activation\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dp1(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Linear links in between + Dropout + Activation\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp2(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._up_to_features(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class NetPosition(nn.Module):\n",
    "    \"\"\" Position Prediction model class \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding_mode='zeros', device=DEVICE)  # Increased filters\n",
    "        self.bn1 = nn.BatchNorm2d(16, device=DEVICE)  # Batch normalization\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dp1 = nn.Dropout2d(0.25)  # Dropout\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, device=DEVICE)  # Increased filters\n",
    "        self.bn2 = nn.BatchNorm2d(32, device=DEVICE)  # Batch normalization\n",
    "\n",
    "        self.fc1 = nn.Linear(5408, 120, device=DEVICE)  # Adjusted input size\n",
    "        self.dp2 = nn.Dropout(0.5)  # Dropout after fully connected\n",
    "        self.fc2 = nn.Linear(120, 48, device=DEVICE)\n",
    "        self.fc3 = nn.Linear(48, 5, device=DEVICE)\n",
    "        self.fc4 = nn.Linear(5, 2, device=DEVICE) # x and y\n",
    "\n",
    "    def _up_to_features(self, x):\n",
    "        # Conv1 + BatchNorm + Activation\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dp1(x)\n",
    "\n",
    "        # Conv2 + BatchNorm + Activation\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dp1(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Linear links in between + Dropout + Activation\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp2(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._up_to_features(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bfec49c6-655d-4392-a677-8db75eaa3b82",
   "metadata": {
    "id": "UHOrDj-X87Zv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Net Reset\n"
     ]
    }
   ],
   "source": [
    "# [Hachem] Init PlumeNoPlume CNN here\n",
    "net = Net() \n",
    "net = net.to(DEVICE)\n",
    "print(\"Model Net Reset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c9a9ce03-8653-48eb-aa5d-df53ede89353",
   "metadata": {
    "id": "UHOrDj-X87Zv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions model reset\n"
     ]
    }
   ],
   "source": [
    "# [Hachem] Init PlumePositions CNN here\n",
    "net_positions = NetPosition()\n",
    "net_positions = net_positions.to(DEVICE)\n",
    "print(\"Positions model reset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6cd95047-76ca-4bdb-bfd9-e650b7612e15",
   "metadata": {
    "id": "UHOrDj-X87Zv"
   },
   "outputs": [],
   "source": [
    "# [Hachem] Define functions for calculating truth table [False, True, True, ....] that is further used for validation\n",
    "def truth_table_plume_noplume(predicted, labels):\n",
    "    \"\"\" \n",
    "    Calculates truth table for label prediction\n",
    "    Inputs :\n",
    "        - predicted : Values predicted by the model\n",
    "        - expected : Expected values\n",
    "    Outputs :\n",
    "        - Truth table\n",
    "    \"\"\"\n",
    "    return torch.round(predicted).squeeze()==labels.squeeze()\n",
    "\n",
    "# [Hachem] Same thing but for positions. It is essential to define epsilon as it will consider two points the same if they are epsilon apart.\n",
    "def truth_table_position(predicted, expected, epsilon = 1e-4):\n",
    "    \"\"\"\n",
    "    Calculates truth table for position prediction\n",
    "    Epsilon gives the verification radius\n",
    "    Inputs :\n",
    "        - predicted : Values predicted by the model\n",
    "        - expected : Expected values\n",
    "        - epsilon : Tolerated distance between two points\n",
    "    Outputs :\n",
    "        - Truth table\n",
    "    \"\"\"\n",
    "    return (torch.pow(predicted - expected, 2).sum(1).sqrt() < epsilon)\n",
    "\n",
    "def evaluate_accuracy(model, dataloader, truth_table_function):\n",
    "    \"\"\"\n",
    "    Inputs : \n",
    "        - model : model to evaluate\n",
    "        - dataloader : DataLoader on which to run the evaluation\n",
    "        - truth_table_function : Truth function used to calculate accuracy\n",
    "    Outputs :\n",
    "        - Accuracy on given set.\n",
    "    \"\"\"\n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # [Hachem] Train accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, data in enumerate(dataloader):\n",
    "            # [Hachem] Extract data and put in GPU (eventually)\n",
    "            images, results = data\n",
    "            images, results = images.to(DEVICE), results.to(DEVICE)\n",
    "\n",
    "            # Get outputs\n",
    "            predicted = model(images)\n",
    "\n",
    "            # Increment accordingly total and correct\n",
    "            total += results.size(dim=0)\n",
    "            correct += truth_table_function(predicted, results).sum().item()\n",
    "        \n",
    "        print(f'Accuracy of the model on train images: {100 * correct / total}%')\n",
    "\n",
    "    # Return accuracy\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "WxadE25pQ-aD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "WxadE25pQ-aD",
    "outputId": "26b6f102-d02f-4453-a2f6-0dccb104ef85"
   },
   "outputs": [],
   "source": [
    "# [Hachem] Define loss function and optimization algorithm\n",
    "PRINT_EPOCHS_FREQUENCY = 10\n",
    "\n",
    "def train_model_one_epoch(model, trainloader, loss_criterion, optimizer ):\n",
    "    \"\"\"\n",
    "    Trains model over one epoch\n",
    "    Inputs :\n",
    "        - model : model to train over one epoch\n",
    "        - trainloader : DataLoader containing the training DataSet\n",
    "        - loss_criterion : Loss function to use\n",
    "        - optimizer : optimizer in use for training\n",
    "    Ouputs :\n",
    "        - running loss at the end of training\n",
    "    \"\"\"\n",
    "    criterion = loss_criterion\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    counter = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        counter += 1\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        # [hachem] Set training mode\n",
    "        model.train()\n",
    "\n",
    "        # labels = labels.long();\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        if outputs.size(0) > 1:\n",
    "            outputs = outputs.squeeze()\n",
    "        else:\n",
    "            outputs = outputs.view(-1)\n",
    "\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    return running_loss\n",
    "\n",
    "def train_net(model, trainloader, validationloader, numofepochs = 100, save_when_accuracy_higher_than = 0.82, save_multiplier = 1.001):\n",
    "    \"\"\"\n",
    "    Trains Classifier Network\n",
    "    Inputs :\n",
    "        - model : Model to train\n",
    "        - trainloader : DataLoader for training\n",
    "        - validationloader : DataLoader for validation\n",
    "        - numofepochs : Number of epochs of training\n",
    "        - save_when_accuracy_higher_than : Save file if accuracy goes beyond this value\n",
    "        - save_miltiplier : Multiplication coefficient for further saves.\n",
    "    Outputs :\n",
    "        None.\n",
    "    \"\"\"\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=0.001)\n",
    "    \n",
    "    # [Hachem] Train    \n",
    "    print(\"Size of training set : ~ \", len(trainloader) * BATCH_SIZE)\n",
    "    print(\"Size of validation set : ~ \", len(validationloader) * BATCH_SIZE)\n",
    "    \n",
    "    for epoch in range(numofepochs):  # loop over the dataset multiple times\n",
    "        # Run training for this epoch.\n",
    "        running_loss = train_model_one_epoch(model, trainloader, criterion, optimizer)\n",
    "        # Depending on PRINT_EPOCHS_FREQUENCY :\n",
    "        if epoch % PRINT_EPOCHS_FREQUENCY == 0:\n",
    "            print(f'[{epoch + 1}] loss: {running_loss / BATCH_SIZE:.3f}')\n",
    "            # Print train accuracy\n",
    "            evaluate_accuracy(model, trainloader, truth_table_plume_noplume) \n",
    "            # Print validation accuracy\n",
    "            validation_accuracy = evaluate_accuracy(model, validationloader, truth_table_plume_noplume)\n",
    "            if validation_accuracy > save_when_accuracy_higher_than:\n",
    "                print(\"Saving model\");\n",
    "                torch.save(net.state_dict(), PREPENDING_PATH + \"best_classifier_model.pt\")\n",
    "                max_result = correct/total * save_multiplier\n",
    "\n",
    "def train_net_position(model, trainloader, validationloader, numofepochs = 100, epsilon = 0.1, save_when_accuracy_higher_than = 0.82, save_multiplier = 1.001):\n",
    "    \"\"\"\n",
    "    Trains Position Predicting Network\n",
    "    Inputs :\n",
    "        - model : Model to train\n",
    "        - trainloader : DataLoader for training\n",
    "        - validationloader : DataLoader for validation\n",
    "        - numofepochs : Number of epochs of training\n",
    "        - epsilon : Tolerated distance for validation\n",
    "        - save_when_accuracy_higher_than : Save file if accuracy goes beyond this value\n",
    "        - save_miltiplier : Multiplication coefficient for further saves.\n",
    "    Outputs :\n",
    "        None.\n",
    "    \"\"\"\n",
    "    criterion = nn.HingeEmbeddingLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    print(\"Size of training set : ~ \", len(trainloader) * BATCH_SIZE)\n",
    "    print(\"Size of validation set : ~ \", len(validationloader) * BATCH_SIZE)\n",
    "    \n",
    "    for epoch in range(numofepochs):  # loop over the dataset multiple times\n",
    "        # Run training for this epoch.\n",
    "        running_loss = train_model_one_epoch(model, trainloader, criterion, optimizer)\n",
    "        # Depending on PRINT_EPOCHS_FREQUENCY :\n",
    "        if epoch % PRINT_EPOCHS_FREQUENCY == 0:\n",
    "            print(f'[{epoch + 1}] loss: {running_loss / BATCH_SIZE:.3f}')\n",
    "            # Print train accuracy\n",
    "            evaluate_accuracy(model, trainloader, truth_table_plume_noplume) \n",
    "            # Print validation accuracy\n",
    "            validation_accuracy = evaluate_accuracy(model, validationloader, truth_table_position)\n",
    "            if validation_accuracy > save_when_accuracy_higher_than:\n",
    "                print(\"Saving model\");\n",
    "                torch.save(net.state_dict(), PREPENDING_PATH + \"best_positions_model.pt\")\n",
    "                max_result = correct/total * save_multiplier    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7bbdd1-1b95-4c5f-9ddf-70ca654887e9",
   "metadata": {},
   "source": [
    "# 5. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1c16a61b-f723-4e45-992a-d801976e26b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training Classifier CNN\n",
      "Size of training set : ~  3104\n",
      "Size of validation set : ~  120\n",
      "[1] loss: 3.980\n",
      "Accuracy of the model on train images: 80.83870967741936%\n",
      "Accuracy of the model on train images: 77.5%\n",
      "[11] loss: 3.882\n",
      "Accuracy of the model on train images: 81.96774193548387%\n",
      "Accuracy of the model on train images: 78.33333333333333%\n",
      "[21] loss: 3.748\n",
      "Accuracy of the model on train images: 84.87096774193549%\n",
      "Accuracy of the model on train images: 80.0%\n",
      "[31] loss: 3.627\n",
      "Accuracy of the model on train images: 84.83870967741936%\n",
      "Accuracy of the model on train images: 76.66666666666667%\n",
      "[41] loss: 3.455\n",
      "Accuracy of the model on train images: 86.38709677419355%\n",
      "Accuracy of the model on train images: 77.5%\n",
      "[51] loss: 3.360\n",
      "Accuracy of the model on train images: 87.48387096774194%\n",
      "Accuracy of the model on train images: 77.5%\n",
      "[61] loss: 3.279\n",
      "Accuracy of the model on train images: 86.83870967741936%\n",
      "Accuracy of the model on train images: 75.0%\n",
      "[71] loss: 3.004\n",
      "Accuracy of the model on train images: 89.25806451612904%\n",
      "Accuracy of the model on train images: 77.5%\n",
      "[81] loss: 2.866\n",
      "Accuracy of the model on train images: 91.3225806451613%\n",
      "Accuracy of the model on train images: 79.16666666666667%\n",
      "[91] loss: 2.683\n",
      "Accuracy of the model on train images: 91.74193548387096%\n",
      "Accuracy of the model on train images: 75.0%\n",
      "[101] loss: 2.540\n",
      "Accuracy of the model on train images: 92.61290322580645%\n",
      "Accuracy of the model on train images: 73.33333333333333%\n",
      "[111] loss: 2.438\n",
      "Accuracy of the model on train images: 93.80645161290323%\n",
      "Accuracy of the model on train images: 76.66666666666667%\n",
      "[121] loss: 2.317\n",
      "Accuracy of the model on train images: 94.29032258064517%\n",
      "Accuracy of the model on train images: 73.33333333333333%\n",
      "[131] loss: 2.085\n",
      "Accuracy of the model on train images: 95.16129032258064%\n",
      "Accuracy of the model on train images: 73.33333333333333%\n",
      "[141] loss: 1.966\n",
      "Accuracy of the model on train images: 96.0%\n",
      "Accuracy of the model on train images: 73.33333333333333%\n",
      "[151] loss: 1.903\n",
      "Accuracy of the model on train images: 96.6774193548387%\n",
      "Accuracy of the model on train images: 72.5%\n",
      "[161] loss: 1.721\n",
      "Accuracy of the model on train images: 97.61290322580645%\n",
      "Accuracy of the model on train images: 75.0%\n",
      "[171] loss: 1.539\n",
      "Accuracy of the model on train images: 97.7741935483871%\n",
      "Accuracy of the model on train images: 72.5%\n",
      "[181] loss: 1.481\n",
      "Accuracy of the model on train images: 98.35483870967742%\n",
      "Accuracy of the model on train images: 74.16666666666667%\n",
      "[191] loss: 1.380\n",
      "Accuracy of the model on train images: 98.6774193548387%\n",
      "Accuracy of the model on train images: 75.0%\n",
      "[201] loss: 1.307\n",
      "Accuracy of the model on train images: 98.90322580645162%\n",
      "Accuracy of the model on train images: 74.16666666666667%\n",
      "[211] loss: 1.157\n",
      "Accuracy of the model on train images: 99.25806451612904%\n",
      "Accuracy of the model on train images: 76.66666666666667%\n",
      "[221] loss: 1.040\n",
      "Accuracy of the model on train images: 99.25806451612904%\n",
      "Accuracy of the model on train images: 75.83333333333333%\n",
      "[231] loss: 1.031\n",
      "Accuracy of the model on train images: 99.45161290322581%\n",
      "Accuracy of the model on train images: 75.83333333333333%\n",
      "[241] loss: 0.911\n",
      "Accuracy of the model on train images: 99.54838709677419%\n",
      "Accuracy of the model on train images: 75.83333333333333%\n",
      "[251] loss: 0.916\n",
      "Accuracy of the model on train images: 99.54838709677419%\n",
      "Accuracy of the model on train images: 76.66666666666667%\n",
      "[261] loss: 0.854\n",
      "Accuracy of the model on train images: 99.58064516129032%\n",
      "Accuracy of the model on train images: 75.83333333333333%\n",
      "[271] loss: 0.843\n",
      "Accuracy of the model on train images: 99.6774193548387%\n",
      "Accuracy of the model on train images: 78.33333333333333%\n",
      "[281] loss: 0.680\n",
      "Accuracy of the model on train images: 99.6774193548387%\n",
      "Accuracy of the model on train images: 75.0%\n",
      "[291] loss: 0.754\n",
      "Accuracy of the model on train images: 99.6774193548387%\n",
      "Accuracy of the model on train images: 76.66666666666667%\n",
      "[301] loss: 0.615\n",
      "Accuracy of the model on train images: 99.74193548387096%\n",
      "Accuracy of the model on train images: 76.66666666666667%\n",
      "[311] loss: 0.652\n",
      "Accuracy of the model on train images: 99.74193548387096%\n",
      "Accuracy of the model on train images: 75.0%\n",
      "[321] loss: 0.617\n",
      "Accuracy of the model on train images: 99.74193548387096%\n",
      "Accuracy of the model on train images: 75.83333333333333%\n",
      "[331] loss: 0.539\n",
      "Accuracy of the model on train images: 99.74193548387096%\n",
      "Accuracy of the model on train images: 75.83333333333333%\n",
      "[341] loss: 0.546\n",
      "Accuracy of the model on train images: 99.74193548387096%\n",
      "Accuracy of the model on train images: 76.66666666666667%\n",
      "[351] loss: 0.573\n",
      "Accuracy of the model on train images: 99.74193548387096%\n",
      "Accuracy of the model on train images: 77.5%\n",
      "[361] loss: 0.504\n",
      "Accuracy of the model on train images: 99.74193548387096%\n",
      "Accuracy of the model on train images: 76.66666666666667%\n",
      "[371] loss: 0.471\n",
      "Accuracy of the model on train images: 99.74193548387096%\n",
      "Accuracy of the model on train images: 78.33333333333333%\n",
      "[381] loss: 0.465\n",
      "Accuracy of the model on train images: 99.7741935483871%\n",
      "Accuracy of the model on train images: 75.83333333333333%\n",
      "[391] loss: 0.447\n",
      "Accuracy of the model on train images: 99.7741935483871%\n",
      "Accuracy of the model on train images: 78.33333333333333%\n",
      "Finished Training CNN Net\n"
     ]
    }
   ],
   "source": [
    "# Train Net network\n",
    "if True:\n",
    "    print(\"Now training Classifier CNN\")\n",
    "    train_net(net, trainloader_plumenoplume, validationloader_plumenoplume, 400)\n",
    "    print('Finished Training CNN Net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ea51a925-7eb3-47d4-b0dd-1735fc4a8fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training Position CNN\n",
      "Size of training set : ~  1568\n",
      "Size of validation set : ~  64\n",
      "[1] loss: 24.227\n",
      "Accuracy of the model on train images: 1.9218449711723253%\n",
      "Accuracy of the model on train images: 0.0%\n",
      "Now Position CNN finished\n"
     ]
    }
   ],
   "source": [
    "# Train Positions Network\n",
    "if True:\n",
    "    print(\"Now training Position CNN\")\n",
    "    number_of_epochs_for_position_training = 10\n",
    "    epsilon_distance = 0.2\n",
    "    train_net_position(net_positions, trainloader_positions, validationloader_positions, number_of_epochs_for_position_training, epsilon_distance)\n",
    "    print(\"Now Position CNN finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6cRjfF-6SSsi",
   "metadata": {
    "id": "6cRjfF-6SSsi"
   },
   "outputs": [],
   "source": [
    "# Note : the following code was not as successful.\n",
    "# [Hachem] Train XGBoost with a well-chosen (hopefully) hidden layer from CNN.\n",
    "features_train_xgboost = []\n",
    "labels_train_xgboost = []\n",
    "\n",
    "features_validation_xgboost = []\n",
    "labels_validation_xgboost = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in trainloader_plumenoplume:\n",
    "        data = data.to(device)\n",
    "        output = F.relu(net._up_to_features(data).to('cpu'))\n",
    "        features_train_xgboost.extend(output.numpy())\n",
    "        labels_train_xgboost.extend(target.numpy())\n",
    "\n",
    "    for data, target in validationloader_plumenoplume:\n",
    "        data = data.to(device)\n",
    "        output = F.relu(net._up_to_features(data).to('cpu'))\n",
    "        features_validation_xgboost.extend(output.numpy())\n",
    "        labels_validation_xgboost.extend(target.numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "features_train_xgboost = np.array(features_train_xgboost)\n",
    "features_validation_xgboost = np.array(features_validation_xgboost)\n",
    "labels_train_xgboost = np.array(labels_train_xgboost)\n",
    "labels_validation_xgboost = np.array(labels_validation_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "YzgoneNMLK5j",
   "metadata": {
    "id": "YzgoneNMLK5j"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Convert to DMatrix\n",
    "dtrain = xgb.DMatrix(features_train_xgboost, label=labels_train_xgboost)\n",
    "\n",
    "# Set parameters and train\n",
    "params = {\n",
    "    'max_depth': 2,\n",
    "    'eta': 0.01,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "num_round = 100\n",
    "bst = xgb.train(params, dtrain, num_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "SyoPXVlTLbQR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyoPXVlTLbQR",
    "outputId": "263cd2c3-6cee-415d-d0f1-47e539508703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 0. 1. 1.]\n",
      "Accuracy of the model + XGBoost on train images: 76.74%\n",
      "Accuracy of the model + XGBoost on validation images: 60.00%\n"
     ]
    }
   ],
   "source": [
    "# [Hachem] CNN + XGBoost Train accuracy\n",
    "predict_train_xgboost = bst.predict(dtrain)\n",
    "predict_train_xgboost = np.round(predict_train_xgboost)\n",
    "\n",
    "print(predict_train_xgboost)\n",
    "accuracy = np.sum(predict_train_xgboost == labels_train_xgboost) / len(labels_train_xgboost)\n",
    "print(f'Accuracy of the model + XGBoost on train images: {100 * accuracy:.2f}%')\n",
    "\n",
    "\n",
    "# [Hachem] CNN + XGBoost validation accuracy\n",
    "dvalidation = xgb.DMatrix(features_validation_xgboost)\n",
    "\n",
    "predict_validation_xgboost = bst.predict(dvalidation)\n",
    "predict_validation_xgboost = np.round(predict_validation_xgboost)\n",
    "\n",
    "accuracy = np.sum(predict_validation_xgboost == labels_validation_xgboost) / len(labels_validation_xgboost)\n",
    "print(f'Accuracy of the model + XGBoost on validation images: {100 * accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5f701-7a2e-4c42-995e-4332f07a3845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
